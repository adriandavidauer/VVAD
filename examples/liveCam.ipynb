{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VVADLRS3 Pretrained Models live in action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vvadlrs3 import sample, dlibmodels\n",
    "import numpy as np\n",
    "import dlib\n",
    "from dvg_ringbuffer import RingBuffer\n",
    "\n",
    "# create a sample\n",
    "k = 36  # Number of frames used for inference\n",
    "shape = (96, 96)  # Resolution of the input imgae for the prediction\n",
    "featureType = 'faceImage'  # Type of the features that will be created from the Image\n",
    "# TODO: this should actually only be needed if not using faceImage type\n",
    "shapeModelPath = str(dlibmodels.SHAPE_PREDICTOR_68_FACE_LANDMARKS())\n",
    "ffg = sample.FaceFeatureGenerator(\n",
    "    featureType, shapeModelPath=shapeModelPath, shape=shape)\n",
    "\n",
    "# TODO: Fist approach only with a detector - later we can try FaceTracker for multiple faces?\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Ringbuffer for features\n",
    "rb = RingBuffer(36, dtype=(np.uint8, (96, 96, 3)))\n",
    "\n",
    "samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Model Overview\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 36, 9216)          3228864   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                1183872   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 4,430,273\n",
      "Trainable params: 4,408,321\n",
      "Non-trainable params: 21,952\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model input shape\n",
      "(None, 36, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "from vvadlrs3 import pretrained_models\n",
    "\n",
    "model = pretrained_models.getFaceImageModel()\n",
    "\n",
    "print('Model Overview')\n",
    "print(model.summary())\n",
    "print('Model input shape')\n",
    "print(model.layers[0].input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.fhog_object_detector, image: array, upsample_num_times: int=0) -> _dlib_pybind11.rectangles\n\nInvoked with: <_dlib_pybind11.fhog_object_detector object at 0x7f0adc0c7330>, None, 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ee40bcc3a2a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# TODO: this is problematic because it runs on the default framerate but we need 25fps for ideal results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# Capture frame-by-frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Detect faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.fhog_object_detector, image: array, upsample_num_times: int=0) -> _dlib_pybind11.rectangles\n\nInvoked with: <_dlib_pybind11.fhog_object_detector object at 0x7f0adc0c7330>, None, 1"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from vvadlrs3.utils.imageUtils import cropImage\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # TODO: this is problematic because it runs on the default framerate but we need 25fps for ideal results\n",
    "    ret, frame = cap.read()     # Capture frame-by-frame\n",
    "    dets = detector(frame, 1)   # Detect faces\n",
    "    if dets:\n",
    "        features = ffg.getFeatures(cropImage(frame, dets[0]))\n",
    "        # fill ringbuffer\n",
    "        rb.append(features)\n",
    "\n",
    "        if rb.is_full:\n",
    "            y = model.predict(np.array([rb]))\n",
    "            s = sample.FeatureizedSample()\n",
    "            s.data = np.copy(rb)\n",
    "            s.label = y > 0.5\n",
    "            s.featureType = featureType\n",
    "            samples.append(s)\n",
    "            print(f\"added sample {len(samples)}\")\n",
    "        cv2.imshow('frame', frame)\n",
    "    else:\n",
    "        # empty ringbuffer - to prevent glitches\n",
    "        rb.clear()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywebrtc import CameraStream, ImageRecorder, VideoRecorder, AudioRecorder\n",
    "from ipywidgets import Image, HBox\n",
    "import PIL.Image\n",
    "import io\n",
    "import numpy as np\n",
    "from skimage.filters import sobel\n",
    "from skimage.color.adapt_rgb import adapt_rgb, each_channel\n",
    "from skimage import filters\n",
    "camera = CameraStream(constraints=\n",
    "                      {'facing_mode': 'user',\n",
    "                       'audio': False,\n",
    "                       'video': { 'width': 640, 'height': 480 },\n",
    "                        \"frameRate\": {\n",
    "                            \"min\": \"1\",\n",
    "                            \"max\": \"1\"\n",
    "                        }})\n",
    "image_recorder = ImageRecorder(stream=camera)\n",
    "type(image_recorder.image.value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bab3779b82467aa31906a39183bd8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), ImageRecorder(image=Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\\x80â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = Image()\n",
    "stop_process = False\n",
    "output = widgets.Output()\n",
    "\n",
    "@output.capture()\n",
    "def process_image(_):\n",
    "    print(\"new Image\")\n",
    "    if stop_process:\n",
    "        return\n",
    "    im_in = PIL.Image.open(io.BytesIO(image_recorder.image.value))\n",
    "    im_array = np.array(im_in)[...,:3]\n",
    "    dets = detector(im_array, 1)   # Detect faces\n",
    "    print(dets)\n",
    "    if dets:\n",
    "        features = ffg.getFeatures(cropImage(frame, dets[0]))\n",
    "        # fill ringbuffer\n",
    "        rb.append(features)\n",
    "\n",
    "        if rb.is_full:\n",
    "            y = model.predict(np.array([rb]))\n",
    "            s = sample.FeatureizedSample()\n",
    "            s.data = np.copy(rb)\n",
    "            s.label = y > 0.5\n",
    "            s.featureType = featureType\n",
    "            samples.append(s)\n",
    "            print(f\"added sample {len(samples)}\")\n",
    "    image_recorder.recording = True\n",
    "\n",
    "image_recorder.image.observe(process_image, names=['value'])\n",
    "#display(image_recorder)\n",
    "#display(output)\n",
    "\n",
    "HBox([output, image_recorder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RingBuffer of array([], shape=(0, 96, 96, 3), dtype=uint8)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples\n",
    "rb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_process = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Widget\n",
    "Widget.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc03515346744288ab76a8c3060d468d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExampleButton(description='Click Me!', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e17afef8e54743a149c8b260eea1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "class ExampleButton(widgets.Button):\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    @output.capture()\n",
    "    def on_button_clicked(b):\n",
    "        print(\"Button clicked.\")\n",
    "        \n",
    "button = ExampleButton(description=\"Click Me!\")\n",
    "display(button)\n",
    "\n",
    "button.on_click(ExampleButton.on_button_clicked)\n",
    "display(ExampleButton.output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('vvadlrs3': conda)",
   "language": "python",
   "name": "python3710jvsc74a57bd0a45b317d13a717d32906abc0c86d086ecd203dc88ba75eaf69b739bb71a49baa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "a45b317d13a717d32906abc0c86d086ecd203dc88ba75eaf69b739bb71a49baa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
